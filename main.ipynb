{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ignore warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the necessary folders to manipulate the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Delete _datasets folder if exists.\n",
      "Create _datasets _datasets/csv _datasets/parquet _datasets/zipped.\n"
     ]
    }
   ],
   "source": [
    "!echo \"\" \n",
    "!echo \"Delete _datasets folder if exists.\"\n",
    "%rm -rf _datasets\n",
    "!echo \"Create _datasets _datasets/csv _datasets/parquet _datasets/zipped.\"\n",
    "%mkdir _datasets\n",
    "%mkdir _datasets/csv\n",
    "%mkdir _datasets/parquet\n",
    "%mkdir _datasets/zipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a function to extract ZIP from URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_from_enem(year : str) -> bool:\n",
    "    \"\"\"\n",
    "    Extract data about Exame Nacional do Ensino Médio (ENEM) during an specific given period.\n",
    "\n",
    "    Args: \n",
    "        year (str): given period.\n",
    "\n",
    "    Returns:\n",
    "        0 if any error has been generated during downloading process. \n",
    "        1 if no error has been generated during downloading process.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        url = \"https://download.inep.gov.br/microdados/microdados_enem_{year}.zip\".format(year=year)\n",
    "        output = \"_datasets/zipped/micro-dados-enem-{year}.zip\".format(year=year)\n",
    "        print(f\"\\nDownloading zipped file from {url}...\")\n",
    "        urllib.request.urlretrieve(url, output)\n",
    "        print(f\"Zipped file wrote in {output}.\")\n",
    "        return True\n",
    "    except:\n",
    "        print(\"\\nError during zipped file downloading proccess.\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the ZIP file using the function created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading zipped file from https://download.inep.gov.br/microdados/microdados_enem_2020.zip...\n",
      "Zipped file wrote in _datasets/zipped/micro-dados-enem-2020.zip.\n",
      "\n",
      "Downloading zipped file from https://download.inep.gov.br/microdados/microdados_enem_2021.zip...\n",
      "Zipped file wrote in _datasets/zipped/micro-dados-enem-2021.zip.\n",
      "\n",
      "Downloading zipped file from https://download.inep.gov.br/microdados/microdados_enem_2022.zip...\n",
      "Zipped file wrote in _datasets/zipped/micro-dados-enem-2022.zip.\n",
      "\n",
      "Downloading zipped file from https://download.inep.gov.br/microdados/microdados_enem_2023.zip...\n",
      "Zipped file wrote in _datasets/zipped/micro-dados-enem-2023.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True, True, True, True]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[extract_data_from_enem(year=year) for year in [\"2020\", \"2021\", \"2022\", \"2023\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unzip the CSV file from ZIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unzipping file micro-dados-enem-2020.zip from _datasets/zipped...\n",
      "Moving file micro-dados-enem-2020.csv to _datasets/csv...\n",
      "CSV file moved to _datasets/csv/micro-dados-enem-2020.csv.\n",
      "\u001b[H\u001b[2J\n",
      "Unzipping file micro-dados-enem-2021.zip from _datasets/zipped...\n",
      "Moving file micro-dados-enem-2021.csv to _datasets/csv...\n",
      "CSV file moved to _datasets/csv/micro-dados-enem-2021.csv.\n",
      "\u001b[H\u001b[2J\n",
      "Unzipping file micro-dados-enem-2022.zip from _datasets/zipped...\n",
      "Moving file micro-dados-enem-2022.csv to _datasets/csv...\n",
      "CSV file moved to _datasets/csv/micro-dados-enem-2022.csv.\n",
      "\u001b[H\u001b[2J\n",
      "Unzipping file micro-dados-enem-2023.zip from _datasets/zipped...\n",
      "Moving file micro-dados-enem-2023.csv to _datasets/csv...\n",
      "CSV file moved to _datasets/csv/micro-dados-enem-2023.csv.\n",
      "\u001b[H\u001b[2J"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "for YEAR in {2020..2023}\n",
    "do\n",
    "    echo \"\"\n",
    "    echo \"Unzipping file micro-dados-enem-$YEAR.zip from _datasets/zipped...\"\n",
    "    unzip -qq \"_datasets/zipped/micro-dados-enem-$YEAR.zip\"\n",
    "    echo \"Moving file micro-dados-enem-$YEAR.csv to _datasets/csv...\"\n",
    "    mv \"DADOS/MICRODADOS_ENEM_$YEAR.csv\" \"_datasets/csv/micro-dados-enem-$YEAR.csv\"\n",
    "    echo \"CSV file moved to _datasets/csv/micro-dados-enem-$YEAR.csv.\"\n",
    "    rm -rf \"DADOS\" \"DICIONÁRIO\" \"INPUTS\" \"LEIA-ME E DOCUMENTOS TÉCNICOS\" \"PROVAS E GABARITOS\"\n",
    "    clear\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming the CSV to PARQUET files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading CSV file micro-dados-enem-2020.csv from _datasets/csv...\n",
      "Transforming micro-dados-enem-2020.csv to micro-dados-enem-2020-00.parquet...\n",
      "Transforming micro-dados-enem-2020.csv to micro-dados-enem-2020-01.parquet...\n",
      "Transforming micro-dados-enem-2020.csv to micro-dados-enem-2020-02.parquet...\n",
      "Transforming micro-dados-enem-2020.csv to micro-dados-enem-2020-03.parquet...\n",
      "Transforming micro-dados-enem-2020.csv to micro-dados-enem-2020-04.parquet...\n",
      "Transforming micro-dados-enem-2020.csv to micro-dados-enem-2020-05.parquet...\n",
      "Parquet file wrote in _datasets/parquet/micro-dados-enem-2020.parquet.\n",
      "\n",
      "Reading CSV file micro-dados-enem-2021.csv from _datasets/csv...\n",
      "Transforming micro-dados-enem-2021.csv to micro-dados-enem-2021-00.parquet...\n",
      "Transforming micro-dados-enem-2021.csv to micro-dados-enem-2021-01.parquet...\n",
      "Transforming micro-dados-enem-2021.csv to micro-dados-enem-2021-02.parquet...\n",
      "Transforming micro-dados-enem-2021.csv to micro-dados-enem-2021-03.parquet...\n",
      "Parquet file wrote in _datasets/parquet/micro-dados-enem-2021.parquet.\n",
      "\n",
      "Reading CSV file micro-dados-enem-2022.csv from _datasets/csv...\n",
      "Transforming micro-dados-enem-2022.csv to micro-dados-enem-2022-00.parquet...\n",
      "Transforming micro-dados-enem-2022.csv to micro-dados-enem-2022-01.parquet...\n",
      "Transforming micro-dados-enem-2022.csv to micro-dados-enem-2022-02.parquet...\n",
      "Transforming micro-dados-enem-2022.csv to micro-dados-enem-2022-03.parquet...\n",
      "Parquet file wrote in _datasets/parquet/micro-dados-enem-2022.parquet.\n",
      "\n",
      "Reading CSV file micro-dados-enem-2023.csv from _datasets/csv...\n",
      "Transforming micro-dados-enem-2023.csv to micro-dados-enem-2023-00.parquet...\n",
      "Transforming micro-dados-enem-2023.csv to micro-dados-enem-2023-01.parquet...\n",
      "Transforming micro-dados-enem-2023.csv to micro-dados-enem-2023-02.parquet...\n",
      "Transforming micro-dados-enem-2023.csv to micro-dados-enem-2023-03.parquet...\n",
      "Parquet file wrote in _datasets/parquet/micro-dados-enem-2023.parquet.\n"
     ]
    }
   ],
   "source": [
    "csvFiles = sorted(os.listdir(\"_datasets/csv\"))\n",
    "\n",
    "for file in csvFiles:\n",
    "    print(f\"\\nReading CSV file {file} from _datasets/csv...\")\n",
    "    chunks = pd.read_csv(f\"_datasets/csv/{file}\", delimiter=\";\", encoding=\"latin-1\", chunksize=1_000_000)\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"Transforming {file} to {str(file)[:21]}-0{i}.parquet...\")\n",
    "        chunk.to_parquet(f\"_datasets/parquet/{str(file)[:21]}-0{i}.parquet\", engine=\"pyarrow\", compression=\"snappy\", index=False)\n",
    "    print(f\"Parquet file wrote in _datasets/parquet/{str(file)[:21]}.parquet.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
